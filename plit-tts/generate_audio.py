#!/usr/bin/env python3
from pathlib import Path
from TTS.api import TTS
import torch

slides = [
    {"id": 1, "script": "ì˜¨ë¼ì¸ ê°•ì˜ ì™„ê°•ë¥ , ê²¨ìš° 15%ì˜ˆìš”"},
    {"id": 2, "script": "ì™œ ê·¸ëŸ´ê¹Œìš”?"},
    {"id": 3, "script": "ë°”ìœë°, í™”ë©´ ê³„ì† ë´ì•¼í•˜ì–ì•„ìš”"},
    {"id": 4, "script": "ë©€í‹°íƒœìŠ¤í‚¹? ë‹¹ì—°íˆ ì•ˆë˜ê³ ìš”"},
    {"id": 5, "script": "Plitì€, ë‹¤ë¥´ê²Œ ì ‘ê·¼í–ˆì–´ìš”"},
    {"id": 6, "script": "ë“£ë‹¤ê°€, í•„ìš”í•  ë•Œë§Œ ë³´ë©´ ë¼ìš”"},
    {"id": 7, "script": "ì§„ì§œ ì‚¬ëŒì²˜ëŸ¼, ìì—°ìŠ¤ëŸ¬ìš´ AI ìŒì„±ìœ¼ë¡œìš”"},
    {"id": 8, "script": "ìš´ì „í•˜ë©´ì„œ, ìš´ë™í•˜ë©´ì„œ"},
    {"id": 9, "script": "ì–´ë””ì„œë“ , ë“¤ì„ ìˆ˜ ìˆì–´ìš”"},
]

def main():
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)

    gpu_available = torch.cuda.is_available()
    print(f"GPU: {'âœ“ ì‚¬ìš© ê°€ëŠ¥' if gpu_available else 'âœ— ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)'}")
    if gpu_available:
        print(f"GPU: {torch.cuda.get_device_name(0)}\n")

    print("ğŸš€ TTS ëª¨ë¸ ë¡œë”© ì¤‘...")
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2", gpu=gpu_available)
    print("âœ“ ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")

    for slide in slides:
        print(f"ğŸµ [{slide['id']}/9] {slide['script']}")

        output_path = output_dir / f"slide-{slide['id']}.mp3"

        tts.tts_to_file(
            text=slide["script"],
            language="ko",
            file_path=str(output_path)
        )

        print(f"   âœ“ {output_path}\n")

    print("ğŸ‰ ëª¨ë“  ìŒì„± íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {output_dir.absolute()}")

    audio_files = sorted(output_dir.glob("slide-*.mp3"))
    total_size = sum(f.stat().st_size for f in audio_files) / 1024
    print(f"ğŸ“Š ì´ {len(audio_files)}ê°œ íŒŒì¼, {total_size:.1f} KB")

if __name__ == "__main__":
    main()
